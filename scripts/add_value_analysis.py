#!/usr/bin/env python3
"""
ä»·å€¼åˆ†æå·¥å…·ï¼ˆå¢é‡ç‰ˆï¼‰
è¯»å–å·²å®Œæˆç›¸å…³æ€§åˆ†æçš„CSVï¼Œåªå¯¹is_ernie_related=YESçš„æ¡ç›®è¿›è¡Œä»·å€¼åˆ¤æ–­
"""

import os
import csv
import json
import time
import requests
from datetime import datetime
from typing import Dict, List
from pathlib import Path


class QianfanAPI:
    """ç™¾åº¦åƒå¸†APIå®¢æˆ·ç«¯"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://qianfan.baidubce.com/v2/chat/completions"
        self.model = "ernie-4.5-8k-preview"

    def _call_api_with_retry(
        self,
        messages: List[Dict[str, str]],
        max_retries: int = 3,
        initial_delay: float = 1.0
    ) -> Dict:
        """è°ƒç”¨APIå¹¶å®ç°é‡è¯•æœºåˆ¶"""
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}",
            "X-Appbuilder-Authorization": self.api_key
        }

        payload = {
            "model": self.model,
            "messages": messages,
            "response_format": {"type": "json_object"},
            "temperature": 0.2
        }

        delay = initial_delay
        last_error = None

        for attempt in range(max_retries + 1):
            try:
                response = requests.post(
                    self.base_url,
                    headers=headers,
                    json=payload,
                    timeout=30
                )

                if response.status_code == 200:
                    data = response.json()

                    if data.get("error_code") or data.get("error_msg"):
                        error_msg = data.get("error_msg") or f"é”™è¯¯ç : {data.get('error_code')}"
                        raise Exception(f"åƒå¸†APIé”™è¯¯: {error_msg}")

                    if not data.get("choices") or not data["choices"][0].get("message"):
                        raise Exception("APIè¿”å›æ•°æ®æ ¼å¼å¼‚å¸¸")

                    return data

                elif response.status_code in [429, 500, 502, 503, 504]:
                    last_error = f"HTTP {response.status_code}: {response.text}"
                    if attempt < max_retries:
                        print(f"  âš ï¸  APIè¯·æ±‚å¤±è´¥ ({attempt + 1}/{max_retries + 1}): {last_error}")
                        print(f"  â³ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                        time.sleep(delay)
                        delay *= 2
                        continue
                    raise Exception(last_error)

                else:
                    raise Exception(f"HTTP {response.status_code}: {response.text}")

            except requests.exceptions.Timeout:
                last_error = "è¯·æ±‚è¶…æ—¶"
                if attempt < max_retries:
                    print(f"  âš ï¸  {last_error} ({attempt + 1}/{max_retries + 1})")
                    print(f"  â³ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    delay *= 2
                    continue
                raise Exception(last_error)

            except requests.exceptions.RequestException as e:
                last_error = f"ç½‘ç»œé”™è¯¯: {str(e)}"
                if attempt < max_retries:
                    print(f"  âš ï¸  {last_error} ({attempt + 1}/{max_retries + 1})")
                    print(f"  â³ ç­‰å¾… {delay:.1f} ç§’åé‡è¯•...")
                    time.sleep(delay)
                    delay *= 2
                    continue
                raise Exception(last_error)

        raise Exception(f"è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæœ€åé”™è¯¯: {last_error}")

    def analyze_value(self, title: str, content: str) -> Dict:
        """åˆ†æERNIEç›¸å…³å†…å®¹æ˜¯å¦æœ‰ä»·å€¼"""
        system_prompt = """ä½ æ˜¯ä¸€ä½å†…å®¹ä»·å€¼åˆ†æä¸“å®¶ï¼Œæ“…é•¿åˆ¤æ–­å…³äºERNIEæ–‡å¿ƒå¤§æ¨¡å‹çš„è®¨è®ºæ˜¯å¦æœ‰å®è´¨æ€§ä»·å€¼ã€‚

## æœ‰ä»·å€¼çš„å†…å®¹

### ä¼˜ç‚¹åé¦ˆï¼ˆvalue_type: "ä¼˜ç‚¹"ï¼‰
- ç”¨æˆ·ä½“éªŒåˆ°çš„å…·ä½“ä¼˜åŠ¿ï¼ˆå¦‚é€Ÿåº¦å¿«ã€ç†è§£å‡†ç¡®ç­‰ï¼‰
- ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”åå‘ç°çš„ä¼˜åŠ¿
- å…·ä½“åº”ç”¨åœºæ™¯ä¸­çš„è‰¯å¥½è¡¨ç°

### ç¼ºç‚¹åé¦ˆï¼ˆvalue_type: "ç¼ºç‚¹"ï¼‰
- ç”¨æˆ·é‡åˆ°çš„å…·ä½“é—®é¢˜æˆ–ä¸è¶³
- æ€§èƒ½ã€å‡†ç¡®åº¦ç­‰æ–¹é¢çš„ä¸è¶³
- ä¸å…¶ä»–æ¨¡å‹å¯¹æ¯”åçš„åŠ£åŠ¿

### é—®é¢˜æŠ¥å‘Šï¼ˆvalue_type: "é—®é¢˜"ï¼‰
- ä½¿ç”¨è¿‡ç¨‹ä¸­é‡åˆ°çš„å…·ä½“æŠ€æœ¯é—®é¢˜
- BugæŠ¥å‘Šæˆ–å¼‚å¸¸è¡Œä¸º
- åŠŸèƒ½é™åˆ¶æˆ–ç¼ºå¤±

### é›†æˆéœ€æ±‚ï¼ˆvalue_type: "éœ€æ±‚"ï¼‰
- å¸Œæœ›ä¸å…¶ä»–å·¥å…·/å¹³å°é›†æˆçš„éœ€æ±‚
- åŠŸèƒ½æ”¹è¿›å»ºè®®
- æ–°åŠŸèƒ½è¯·æ±‚

### æ·±åº¦è®¨è®ºï¼ˆvalue_type: "æ·±åº¦è®¨è®º"ï¼‰
- æŠ€æœ¯ç»†èŠ‚åˆ†æ
- æ¶æ„æˆ–åŸç†æ¢è®¨
- åº”ç”¨æ¡ˆä¾‹åˆ†äº«

## æ— ä»·å€¼çš„å†…å®¹

- **å®˜æ–¹é€šç¨¿**ï¼šä»…è½¬å‘å®˜æ–¹æ–°é—»ï¼Œæ— ä¸ªäººè§‚ç‚¹æˆ–ä½“éªŒ
- **æƒ…ç»ªå®£æ³„**ï¼šä»…æœ‰æƒ…ç»ªè¡¨è¾¾ï¼Œæ— å…·ä½“å†…å®¹ï¼ˆå¦‚"å¤ªæ£’äº†ï¼"ã€"å¾ˆå¤±æœ›"ï¼‰
- **ç®€å•è½¬è¿°**ï¼šä»…è½¬è¿°ä»–äººè§‚ç‚¹ï¼Œæ— æ–°ä¿¡æ¯
- **æ— å…³è®¨è®º**ï¼šè™½æåŠERNIEä½†å®é™…è®¨è®ºå…¶ä»–è¯é¢˜
- **spam/å¹¿å‘Š**ï¼šè¥é”€æ€§è´¨å†…å®¹

## è¾“å‡ºè¦æ±‚

ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{
  "has_value": trueæˆ–false,
  "value_type": "ä¼˜ç‚¹/ç¼ºç‚¹/é—®é¢˜/éœ€æ±‚/æ·±åº¦è®¨è®º/æ— ä»·å€¼",
  "value_reason": "ç®€çŸ­è¯´æ˜ï¼ˆä¸­æ–‡ï¼Œä¸è¶…è¿‡50å­—ï¼‰"
}

æ³¨æ„ï¼š
- has_value: trueè¡¨ç¤ºæœ‰ä»·å€¼ï¼Œfalseè¡¨ç¤ºæ— ä»·å€¼
- value_type: å¦‚æœæ— ä»·å€¼åˆ™å¡«"æ— ä»·å€¼"
- value_reason: ç®€è¦è¯´æ˜åˆ¤æ–­ä¾æ®"""

        user_prompt = f"""è¯·åˆ¤æ–­ä»¥ä¸‹å…³äºERNIEçš„è®¨è®ºæ˜¯å¦æœ‰ä»·å€¼ï¼š

æ ‡é¢˜ï¼š{title if title and title.strip() else "æ— æ ‡é¢˜"}

å†…å®¹ï¼š{content if content and content.strip() else "æ— å†…å®¹"}

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºåˆ†æç»“æœã€‚"""

        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt}
        ]

        try:
            response = self._call_api_with_retry(messages)
            content_str = response["choices"][0]["message"]["content"]

            if content_str.strip().startswith("```"):
                lines = content_str.strip().split('\n')
                json_str = '\n'.join(lines[1:-1])
            else:
                json_str = content_str

            result = json.loads(json_str)

            if not all(key in result for key in ["has_value", "value_type", "value_reason"]):
                raise ValueError("APIè¿”å›çš„JSONç¼ºå°‘å¿…éœ€å­—æ®µ")

            return {
                "has_value": bool(result["has_value"]),
                "value_type": str(result["value_type"]),
                "value_reason": str(result["value_reason"])
            }

        except json.JSONDecodeError as e:
            print(f"  âŒ JSONè§£æå¤±è´¥: {e}")
            return {
                "has_value": False,
                "value_type": "æ— ä»·å€¼",
                "value_reason": "APIè¿”å›æ ¼å¼é”™è¯¯ï¼Œæ— æ³•è§£æ"
            }
        except Exception as e:
            print(f"  âŒ ä»·å€¼åˆ†æå¤±è´¥: {e}")
            return {
                "has_value": False,
                "value_type": "æ— ä»·å€¼",
                "value_reason": f"åˆ†æå‡ºé”™: {str(e)}"
            }


class ValueAnalyzer:
    """ä»·å€¼åˆ†æå™¨ï¼ˆå¢é‡ç‰ˆï¼‰"""

    def __init__(self, api_key: str, input_csv: str, output_csv: str = None):
        self.api = QianfanAPI(api_key)
        self.input_csv = input_csv

        if output_csv is None:
            input_path = Path(input_csv)
            output_csv = input_path.parent / f"{input_path.stem}_with_value.csv"

        self.output_csv = output_csv
        self.progress_file = Path(output_csv).with_suffix('.progress.json')

    def load_progress(self) -> Dict:
        """åŠ è½½å¤„ç†è¿›åº¦"""
        if self.progress_file.exists():
            with open(self.progress_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {"processed_ids": [], "last_index": -1}

    def save_progress(self, progress: Dict):
        """ä¿å­˜å¤„ç†è¿›åº¦"""
        with open(self.progress_file, 'w', encoding='utf-8') as f:
            json.dump(progress, f, ensure_ascii=False, indent=2)

    def add_value_analysis(self, batch_size: int = 10):
        """ä¸ºå·²åˆ†æç›¸å…³æ€§çš„æ•°æ®æ·»åŠ ä»·å€¼åˆ¤æ–­"""
        print(f"\n{'='*60}")
        print(f"ERNIEä»·å€¼åˆ†æå·¥å…·ï¼ˆå¢é‡ç‰ˆï¼‰")
        print(f"{'='*60}")
        print(f"è¾“å…¥æ–‡ä»¶: {self.input_csv}")
        print(f"è¾“å‡ºæ–‡ä»¶: {self.output_csv}")
        print(f"è¿›åº¦æ–‡ä»¶: {self.progress_file}")
        print(f"{'='*60}\n")

        # è¯»å–CSV
        print("ğŸ“– æ­£åœ¨è¯»å–CSVæ–‡ä»¶...")
        with open(self.input_csv, 'r', encoding='utf-8-sig') as f:
            reader = csv.DictReader(f)
            rows = list(reader)
            fieldnames = reader.fieldnames

        total_rows = len(rows)
        print(f"âœ“ å…±è¯»å– {total_rows} æ¡è®¨è®º\n")

        # ç»Ÿè®¡éœ€è¦å¤„ç†çš„ç›¸å…³æ¡ç›®
        related_rows = [row for row in rows if row.get('is_ernie_related') == 'YES']
        print(f"âœ“ å…¶ä¸­ {len(related_rows)} æ¡æ ‡è®°ä¸ºERNIEç›¸å…³\n")

        # åŠ è½½è¿›åº¦
        progress = self.load_progress()
        processed_ids = set(progress.get("processed_ids", []))
        start_index = progress.get("last_index", -1) + 1

        if start_index > 0:
            print(f"ğŸ“Œ æ£€æµ‹åˆ°ä¸Šæ¬¡è¿›åº¦ï¼Œä»ç¬¬ {start_index + 1} æ¡ç»§ç»­å¤„ç†\n")

        # æ·»åŠ æ–°å­—æ®µï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
        if 'has_value' not in fieldnames:
            new_fieldnames = list(fieldnames) + ['has_value', 'value_type', 'value_reason']
        else:
            new_fieldnames = list(fieldnames)

        # å‡†å¤‡è¾“å‡ºæ–‡ä»¶
        output_file = open(self.output_csv, 'w', encoding='utf-8-sig', newline='')
        writer = csv.DictWriter(output_file, fieldnames=new_fieldnames)
        writer.writeheader()

        # ç»Ÿè®¡
        success_count = 0
        error_count = 0
        valuable_count = 0
        skipped_count = 0

        start_time = time.time()

        print(f"ğŸš€ å¼€å§‹ä»·å€¼åˆ†æ...\n")

        for i, row in enumerate(rows):
            row_id = row.get('db_id', str(i))

            # å¦‚æœä¸æ˜¯ERNIEç›¸å…³ï¼Œç›´æ¥å†™å…¥
            if row.get('is_ernie_related') != 'YES':
                # å¡«å……ç©ºå€¼
                if 'has_value' not in row or not row.get('has_value'):
                    row['has_value'] = ''
                    row['value_type'] = ''
                    row['value_reason'] = ''
                writer.writerow(row)
                skipped_count += 1
                continue

            # å¦‚æœå·²å¤„ç†è¿‡ï¼Œç›´æ¥å†™å…¥
            if row_id in processed_ids:
                writer.writerow(row)
                continue

            title = row.get('title', '')
            content = row.get('content', '')

            print(f"[{i + 1}/{total_rows}] ä»·å€¼åˆ†æä¸­...", end=' ')

            try:
                # è°ƒç”¨APIåˆ†æä»·å€¼
                value_result = self.api.analyze_value(title, content)

                row['has_value'] = 'YES' if value_result['has_value'] else 'NO'
                row['value_type'] = value_result['value_type']
                row['value_reason'] = value_result['value_reason']

                writer.writerow(row)
                output_file.flush()

                success_count += 1
                if value_result['has_value']:
                    valuable_count += 1
                    print(f"âœ“ æœ‰ä»·å€¼ [{value_result['value_type']}]")
                else:
                    print(f"â—‹ æ— ä»·å€¼ [{value_result['value_type']}]")

                processed_ids.add(row_id)

                # å®šæœŸä¿å­˜è¿›åº¦
                if (success_count) % batch_size == 0:
                    progress = {
                        "processed_ids": list(processed_ids),
                        "last_index": i
                    }
                    self.save_progress(progress)

                    elapsed = time.time() - start_time
                    avg_time = elapsed / success_count if success_count > 0 else 0
                    remaining_related = len(related_rows) - success_count
                    remaining_time = remaining_related * avg_time

                    print(f"\n  ğŸ’¾ è¿›åº¦å·²ä¿å­˜ | å·²åˆ†æ: {success_count}/{len(related_rows)} | "
                          f"æœ‰ä»·å€¼: {valuable_count} | "
                          f"é¢„è®¡å‰©ä½™: {remaining_time/60:.1f}åˆ†é’Ÿ\n")

                # APIé™æµæ§åˆ¶
                time.sleep(0.5)

            except Exception as e:
                error_count += 1
                print(f"âŒ é”™è¯¯: {e}")

                row['has_value'] = 'ERROR'
                row['value_type'] = ''
                row['value_reason'] = f"åˆ†æå¤±è´¥: {str(e)}"
                writer.writerow(row)
                output_file.flush()

                processed_ids.add(row_id)

        output_file.close()

        # å®Œæˆï¼Œåˆ é™¤è¿›åº¦æ–‡ä»¶
        if self.progress_file.exists():
            self.progress_file.unlink()

        # è¾“å‡ºç»Ÿè®¡
        elapsed = time.time() - start_time
        print(f"\n{'='*60}")
        print(f"âœ… ä»·å€¼åˆ†æå®Œæˆï¼")
        print(f"{'='*60}")
        print(f"æ€»è®¡: {total_rows} æ¡")
        print(f"ERNIEç›¸å…³: {len(related_rows)} æ¡")
        print(f"å·²åˆ†æ: {success_count} æ¡")
        print(f"å¤±è´¥: {error_count} æ¡")
        if success_count > 0:
            print(f"æœ‰ä»·å€¼å†…å®¹: {valuable_count} æ¡ ({valuable_count/success_count*100:.1f}%)")
        print(f"è€—æ—¶: {elapsed/60:.1f} åˆ†é’Ÿ")
        print(f"\nç»“æœå·²ä¿å­˜è‡³: {self.output_csv}")
        print(f"{'='*60}\n")


def main():
    """ä¸»å‡½æ•°"""
    api_key = "bce-v3/ALTAK-3t7fjMhp5Bx2KUqiEj4SF/8b44c3fc85f248a4b9b1c7532d0d2fc3f91150bc"

    # è¾“å…¥æ–‡ä»¶ï¼šå·²å®Œæˆç›¸å…³æ€§åˆ†æçš„CSV
    input_csv = "data/exports/discussions_ERNIE_20251117_184548_analyzed_20251119_164621.csv"

    if not os.path.exists(input_csv):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶ {input_csv}")
        return

    analyzer = ValueAnalyzer(
        api_key=api_key,
        input_csv=input_csv
    )

    try:
        analyzer.add_value_analysis(batch_size=10)
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜ï¼Œä¸‹æ¬¡è¿è¡Œå°†ç»§ç»­å¤„ç†")
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        raise


if __name__ == "__main__":
    main()
