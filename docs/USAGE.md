# DiscussionFetcher ä½¿ç”¨æ–‡æ¡£

**è‡ªåŠ¨åŒ–å…¨é‡æŠ“å– HuggingFace å’Œ Reddit è®¨è®ºæ•°æ®**

---

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- âœ… **å®Œå…¨è‡ªåŠ¨åŒ–**ï¼šé…ç½®ä¸€æ¬¡ï¼Œä¹‹åå…¨è‡ªåŠ¨è¿è¡Œ
- âœ… **å…¨é‡æ•°æ®**ï¼šè‡ªåŠ¨æŠ“å–å¤šä¸ªæ¥æºçš„å®Œæ•´æ•°æ®
- âœ… **é›¶æ‰‹åŠ¨æ“ä½œ**ï¼šé™¤äº†é¦–æ¬¡å¯¼å‡º cookiesï¼Œæ— éœ€ä»»ä½•æ‰‹åŠ¨æ“ä½œ
- âœ… **æ™ºèƒ½å»é‡**ï¼šè‡ªåŠ¨åˆå¹¶æ•°æ®ï¼Œé¿å…é‡å¤
- âœ… **Web ç•Œé¢**ï¼šå¯è§†åŒ–æ“ä½œå’Œæ•°æ®æŸ¥çœ‹

---

## ğŸ“¦ æ•°æ®è¦†ç›–èŒƒå›´

### Reddit
- **æ¿å—æ•°é‡**ï¼š9ä¸ªä¸»æµ AI/LLM æ¿å—
  - LocalLLM, LocalLlaMa, ChatGPT
  - ArtificialIntelligence, OpenSourceeAI
  - singularity, machinelearningnews
  - SillyTavernAI, StableDiffusion

- **æ•°æ®ç±»å‹**ï¼š
  - **Postsï¼ˆå¸–å­ï¼‰**ï¼šä½¿ç”¨å®˜æ–¹ API è·å–
  - **Commentsï¼ˆè¯„è®ºï¼‰**ï¼šä½¿ç”¨ Selenium è‡ªåŠ¨æµè§ˆå™¨è·å–

- **æ—¶é—´èŒƒå›´**ï¼š
  - Postsï¼šå…¨éƒ¨å†å²æ•°æ®
  - Commentsï¼šæœ€è¿‘ 30 å¤©ï¼ˆé¿å…æ•°æ®é‡è¿‡å¤§ï¼‰

### HuggingFace
- **æ•°æ®æ¥æº**ï¼šERNIE ç›¸å…³æ¨¡å‹çš„è®¨è®º
- **æ—¶é—´èŒƒå›´**ï¼šå…¨éƒ¨å†å²æ•°æ®

---

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¬¬ä¸€æ­¥ï¼šå®‰è£…ä¾èµ–

```bash
# å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®å
cd DiscussionFetcher_v2.0

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

**ä¾èµ–è¯´æ˜**ï¼š
- `praw`ï¼šReddit å®˜æ–¹ APIï¼ˆè·å– Postsï¼‰
- `selenium`ï¼šæµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼ˆè·å– Commentsï¼‰
- `beautifulsoup4`ï¼šHTML è§£æ
- `pandas`ï¼šæ•°æ®å¤„ç†
- `flask`ï¼šWeb ç•Œé¢

### ç¬¬äºŒæ­¥ï¼šé…ç½® API å‡­è¯ï¼ˆå¯é€‰ï¼‰

Reddit Posts ä½¿ç”¨å®˜æ–¹ APIï¼Œéœ€è¦é…ç½®å‡­è¯ï¼š

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘ .envï¼Œå¡«å…¥ä½ çš„å‡­è¯
# REDDIT_CLIENT_ID=your_client_id
# REDDIT_CLIENT_SECRET=your_client_secret
# REDDIT_USER_AGENT=DiscussionFetcher/1.0
```

**å¦‚ä½•è·å– Reddit API å‡­è¯**ï¼š
1. è®¿é—® https://www.reddit.com/prefs/apps
2. ç‚¹å‡» "Create App" æˆ– "Create Another App"
3. å¡«å†™ä¿¡æ¯ï¼š
   - name: `DiscussionFetcher`
   - type: é€‰æ‹© `script`
   - redirect uri: `http://localhost:8080`
4. åˆ›å»ºåï¼Œå¤åˆ¶ `client_id` å’Œ `client_secret`

> ğŸ’¡ **æç¤º**ï¼šå¦‚æœä¸é…ç½®ï¼Œä»å¯è·å– HuggingFace æ•°æ®å’Œ Reddit Commentsï¼Œåªæ˜¯æ— æ³•è·å– Reddit Postsã€‚

### ç¬¬ä¸‰æ­¥ï¼šå¯¼å‡º Cookiesï¼ˆå”¯ä¸€æ‰‹åŠ¨æ­¥éª¤ï¼‰

**ä¸ºä»€ä¹ˆéœ€è¦ Cookiesï¼Ÿ**
- âœ… é¿å… CAPTCHA éªŒè¯
- âœ… é¿å…ç™»å½•å¼¹çª—
- âœ… é¿å…é™æµï¼ˆå·²ç™»å½•ç”¨æˆ·é™åˆ¶æ›´å°‘ï¼‰
- âœ… è·å–å®Œæ•´å†…å®¹ï¼ˆå‡ ç™¾æ¡è¯„è®º/æ¿å—ï¼‰

**å¯¼å‡ºæ­¥éª¤ï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰ï¼š**

#### æ–¹æ³• 1: ä½¿ç”¨ EditThisCookie æ’ä»¶ï¼ˆæ¨èï¼‰

1. **å®‰è£…æ’ä»¶**
   - Chrome/Edge: https://chrome.google.com/webstore â†’ æœç´¢ "EditThisCookie"
   - Firefox: https://addons.mozilla.org â†’ æœç´¢ "EditThisCookie"

2. **ç™»å½• Reddit**
   - è®¿é—® https://www.reddit.com
   - ç™»å½•ä½ çš„è´¦å·ï¼ˆå¦‚æœæ²¡æœ‰è´¦å·ï¼Œæ³¨å†Œä¸€ä¸ªï¼‰

3. **å¯¼å‡º Cookies**
   - ç‚¹å‡»æµè§ˆå™¨å·¥å…·æ çš„ EditThisCookie å›¾æ ‡ï¼ˆé¥¼å¹²å›¾æ ‡ï¼‰
   - ç‚¹å‡» "Export" æŒ‰é’®ï¼ˆğŸ“¤ å›¾æ ‡ï¼‰
   - Cookies ä¼šè‡ªåŠ¨å¤åˆ¶åˆ°å‰ªè´´æ¿
   - åˆ›å»ºæ–‡ä»¶ `cookies.json`ï¼Œç²˜è´´å†…å®¹å¹¶ä¿å­˜

```bash
# åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º cookies.json
# ç²˜è´´ä» EditThisCookie å¯¼å‡ºçš„å†…å®¹
nano cookies.json  # æˆ–ä½¿ç”¨ä»»ä½•æ–‡æœ¬ç¼–è¾‘å™¨
```

#### æ–¹æ³• 2: ä½¿ç”¨æµè§ˆå™¨å¼€å‘è€…å·¥å…·

1. ç™»å½• Reddit
2. æŒ‰ F12 æ‰“å¼€å¼€å‘è€…å·¥å…·
3. åˆ‡æ¢åˆ° "Application" / "å­˜å‚¨" æ ‡ç­¾
4. å·¦ä¾§é€‰æ‹© "Cookies" â†’ "https://www.reddit.com"
5. æ‰¾åˆ°é‡è¦çš„ cookiesï¼ˆå¦‚ `reddit_session`ï¼‰
6. æŒ‰ç…§ä»¥ä¸‹æ ¼å¼åˆ›å»º `cookies.json`ï¼š

```json
[
  {
    "name": "reddit_session",
    "value": "ä½ çš„_session_å€¼",
    "domain": ".reddit.com"
  }
]
```

**éªŒè¯ Cookies æ˜¯å¦æœ‰æ•ˆ**ï¼š
```bash
python3 -c "from pathlib import Path; print('âœ“ cookies.json å­˜åœ¨' if Path('./cookies.json').exists() else 'âœ— æœªæ‰¾åˆ° cookies.json')"
```

---

## ğŸ® ä½¿ç”¨æ–¹æ³•

### æ–¹å¼ 1: Web ç•Œé¢ï¼ˆæ¨èæ–°æ‰‹ï¼‰

æœ€ç®€å•çš„æ–¹å¼ï¼Œå¯è§†åŒ–æ“ä½œï¼š

```bash
# å¯åŠ¨ Web æœåŠ¡å™¨
./start.sh

# æˆ–æ‰‹åŠ¨å¯åŠ¨
python3 web_server.py
```

ç„¶åè®¿é—®ï¼šhttp://127.0.0.1:5000

**Web ç•Œé¢åŠŸèƒ½**ï¼š
- ğŸ“Š å®æ—¶ç»Ÿè®¡ï¼ˆæ€»æ•°ã€å„å¹³å°æ•°æ®é‡ï¼‰
- ğŸš€ ä¸€é”®æŠ“å–ï¼ˆé€‰æ‹©å¹³å°ã€è¾“å…¥å…³é”®è¯ï¼‰
- ğŸ” æœç´¢å’Œç­›é€‰ï¼ˆå…¨æ–‡æœç´¢ã€æŒ‰å¹³å°ç­›é€‰ï¼‰
- ğŸ’¾ æ•°æ®å¯¼å‡ºï¼ˆCSV/Excel æ ¼å¼ï¼‰
- ğŸ“ æ•°æ®æµè§ˆï¼ˆåˆ†é¡µæŸ¥çœ‹æ‰€æœ‰è®¨è®ºï¼‰

### æ–¹å¼ 2: å‘½ä»¤è¡Œï¼ˆæ¨èè‡ªåŠ¨åŒ–ï¼‰

#### å®Œæ•´æŠ“å–ï¼ˆæ¨èï¼‰

```bash
# ä¸€é”®æŠ“å–æ‰€æœ‰æ•°æ®ï¼ˆPosts + Commentsï¼‰
python3 fetch_all.py --reddit-comments

# è¾“å‡ºç¤ºä¾‹ï¼š
# âœ“ Reddit Posts: 45 æ¡
# âœ“ Reddit Comments: 18 æ¡ï¼ˆæ»šåŠ¨ 5 æ¬¡/æ¿å—ï¼Œæœ€è¿‘30å¤©ï¼‰
# âœ“ HuggingFace: 193 æ¡
# âœ“ æ€»è®¡: 256 æ¡æ•°æ®å·²ä¿å­˜åˆ°æ•°æ®åº“
```

**å‚æ•°è¯´æ˜**ï¼š
- `--reddit-comments`ï¼šåŒæ—¶æŠ“å–è¯„è®ºï¼ˆéœ€è¦ cookies.jsonï¼‰
- `--max-pages N`ï¼šæ¯ä¸ªæ¿å—æœ€å¤šæ»šåŠ¨ N æ¬¡ï¼ˆé»˜è®¤5æ¬¡ï¼Œçº¦100-150æ¡è¯„è®º/æ¿å—ï¼‰
- `--platforms`ï¼šæŒ‡å®šå¹³å°ï¼ˆreddit, huggingface, allï¼‰
- `--cookies`ï¼šæŒ‡å®š cookies æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤ ./cookies.jsonï¼‰

#### é«˜çº§ç”¨æ³•

```bash
# ä»…æŠ“å– Redditï¼ˆä¸å«è¯„è®ºï¼‰
python3 fetch_all.py --platforms reddit

# ä»…æŠ“å– HuggingFace
python3 fetch_all.py --platforms huggingface

# å¢åŠ è¯„è®ºæŠ“å–æ·±åº¦ï¼ˆæ›´å¤šè¯„è®ºï¼Œä½†æ›´æ…¢ï¼‰
python3 fetch_all.py --reddit-comments --max-pages=20

# ä½¿ç”¨è‡ªå®šä¹‰ cookies æ–‡ä»¶
python3 fetch_all.py --reddit-comments --cookies=/path/to/cookies.json
```

### æ–¹å¼ 3: Python APIï¼ˆé«˜çº§ç”¨æˆ·ï¼‰

```python
# 1. æŠ“å– Reddit Posts
from src.reddit import RedditFetcher

reddit = RedditFetcher(verbose=True)
posts = reddit.fetch(query='ERNIE')
print(f"è·å– {len(posts)} ä¸ªå¸–å­")

# 2. æŠ“å– Reddit Commentsï¼ˆéœ€è¦ cookiesï¼‰
from src.reddit_comments_selenium import RedditCommentsSeleniumFetcher

comments_fetcher = RedditCommentsSeleniumFetcher(
    cookies_file='./cookies.json',
    headless=True,  # æ— å¤´æ¨¡å¼ï¼ˆä¸æ˜¾ç¤ºæµè§ˆå™¨ï¼‰
    verbose=True
)
comments = comments_fetcher.fetch(
    query='ERNIE',
    max_scrolls=10,  # æ¯ä¸ªæ¿å—æ»šåŠ¨10æ¬¡
    days_limit=30    # åªè·å–æœ€è¿‘30å¤©
)
print(f"è·å– {len(comments)} æ¡è¯„è®º")

# 3. æŠ“å– HuggingFace
from src.huggingface import HuggingFaceFetcher

hf = HuggingFaceFetcher(verbose=True)
discussions = hf.fetch('ERNIE-4.5')
print(f"è·å– {len(discussions)} æ¡è®¨è®º")
```

---

## ğŸ“Š æŸ¥çœ‹æ•°æ®

### æ–¹å¼ 1: Web ç•Œé¢

è®¿é—® http://127.0.0.1:5000ï¼Œåœ¨ç•Œé¢ä¸­ï¼š
- æŸ¥çœ‹å®æ—¶ç»Ÿè®¡
- æœç´¢å’Œç­›é€‰è®¨è®º
- å¯¼å‡ºæ•°æ®

### æ–¹å¼ 2: å‘½ä»¤è¡Œå·¥å…·

```bash
# æŸ¥çœ‹ç»Ÿè®¡
python3 db_manager.py stats

# å¯¼å‡ºä¸º Excel
python3 db_manager.py export --format excel --output data.xlsx

# å¯¼å‡ºä¸º CSV
python3 db_manager.py export --format csv --output data.csv

# æŒ‰å¹³å°å¯¼å‡º
python3 db_manager.py export --format excel --output reddit_data.xlsx --platform reddit
```

### æ–¹å¼ 3: ç›´æ¥æŸ¥è¯¢æ•°æ®åº“

```python
from src.database import DatabaseManager

db = DatabaseManager()

# æŸ¥è¯¢æœ€è¿‘çš„è®¨è®º
recent = db.get_recent_discussions(limit=10)

# æœç´¢
results = db.search_discussions(keyword='ERNIE', limit=100)

# æŒ‰å¹³å°æŸ¥è¯¢
reddit_posts = db.query_discussions(platform='reddit', content_type='post')
reddit_comments = db.query_discussions(platform='reddit', content_type='comment')
hf_discussions = db.query_discussions(platform='huggingface')
```

æ•°æ®åº“ä½ç½®ï¼š`./data/discussions.db`ï¼ˆSQLiteï¼‰

---

## âš™ï¸ è‡ªåŠ¨åŒ–å®šæ—¶æŠ“å–

### æ–¹æ³• 1: cronï¼ˆLinux/Macï¼‰

```bash
# ç¼–è¾‘ crontab
crontab -e

# æ·»åŠ å®šæ—¶ä»»åŠ¡ï¼ˆæ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œï¼‰
0 2 * * * cd /path/to/DiscussionFetcher_v2.0 && python3 fetch_all.py --reddit-comments >> logs/fetch.log 2>&1
```

### æ–¹æ³• 2: Windows ä»»åŠ¡è®¡åˆ’ç¨‹åº

1. æ‰“å¼€"ä»»åŠ¡è®¡åˆ’ç¨‹åº"
2. åˆ›å»ºåŸºæœ¬ä»»åŠ¡
3. è§¦å‘å™¨ï¼šæ¯å¤©
4. æ“ä½œï¼šå¯åŠ¨ç¨‹åº
   - ç¨‹åºï¼š`python3`
   - å‚æ•°ï¼š`fetch_all.py --reddit-comments`
   - èµ·å§‹äºï¼š`C:\path\to\DiscussionFetcher_v2.0`

### æ–¹æ³• 3: åå°æœåŠ¡ï¼ˆæ¨èï¼‰

åˆ›å»ºä¸€ä¸ªç®€å•çš„ Python è„šæœ¬ `auto_fetch.py`ï¼š

```python
#!/usr/bin/env python3
"""è‡ªåŠ¨å®šæ—¶æŠ“å–è„šæœ¬"""

import time
import schedule
from pathlib import Path
import sys

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.reddit import RedditFetcher
from src.reddit_comments_selenium import RedditCommentsSeleniumFetcher
from src.huggingface import HuggingFaceFetcher

def fetch_all():
    """æ‰§è¡Œå®Œæ•´æŠ“å–"""
    print(f"\n{'='*60}")
    print(f"å¼€å§‹æŠ“å– - {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    # Reddit Posts
    reddit = RedditFetcher(verbose=True)
    reddit.fetch(query='ERNIE')

    # Reddit Comments
    if Path('./cookies.json').exists():
        comments = RedditCommentsSeleniumFetcher(headless=True, verbose=True)
        comments.fetch(query='ERNIE', max_scrolls=10, days_limit=30)

    # HuggingFace
    hf = HuggingFaceFetcher(verbose=True)
    hf.fetch('ERNIE-4.5')

    print(f"\n{'='*60}")
    print(f"æŠ“å–å®Œæˆ - {time.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

# æ¯å¤©å‡Œæ™¨2ç‚¹è¿è¡Œ
schedule.every().day.at("02:00").do(fetch_all)

print("è‡ªåŠ¨æŠ“å–æœåŠ¡å·²å¯åŠ¨")
print("æ¯å¤©å‡Œæ™¨ 02:00 è‡ªåŠ¨è¿è¡Œ")
print("æŒ‰ Ctrl+C åœæ­¢\n")

# é¦–æ¬¡å¯åŠ¨ç«‹å³è¿è¡Œä¸€æ¬¡
fetch_all()

# æŒç»­è¿è¡Œ
while True:
    schedule.run_pending()
    time.sleep(60)
```

è¿è¡Œåå°æœåŠ¡ï¼š
```bash
# å‰å°è¿è¡Œï¼ˆæµ‹è¯•ï¼‰
python3 auto_fetch.py

# åå°è¿è¡Œï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
nohup python3 auto_fetch.py > logs/auto_fetch.log 2>&1 &
```

---

## ğŸ”§ æ€§èƒ½è°ƒä¼˜

### è°ƒæ•´æŠ“å–æ·±åº¦

```bash
# å¿«é€ŸæŠ“å–ï¼ˆæ¯ä¸ªæ¿å—çº¦50æ¡è¯„è®ºï¼‰
python3 fetch_all.py --reddit-comments --max-pages=3

# æ ‡å‡†æŠ“å–ï¼ˆæ¯ä¸ªæ¿å—çº¦100-150æ¡è¯„è®ºï¼Œæ¨èï¼‰
python3 fetch_all.py --reddit-comments --max-pages=5

# æ·±åº¦æŠ“å–ï¼ˆæ¯ä¸ªæ¿å—çº¦200-300æ¡è¯„è®ºï¼‰
python3 fetch_all.py --reddit-comments --max-pages=10

# å®Œæ•´æŠ“å–ï¼ˆæ¯ä¸ªæ¿å—çº¦400-500æ¡è¯„è®ºï¼Œè€—æ—¶é•¿ï¼‰
python3 fetch_all.py --reddit-comments --max-pages=20
```

**æ€§èƒ½å¯¹æ¯”**ï¼š

| æ»šåŠ¨æ¬¡æ•° | è¯„è®ºæ•°/æ¿å— | æ€»è¯„è®ºæ•°ï¼ˆ9ä¸ªæ¿å—ï¼‰ | è€—æ—¶ |
|---------|-----------|------------------|-----|
| 3 æ¬¡ | ~50 æ¡ | ~450 æ¡ | ~2 åˆ†é’Ÿ |
| 5 æ¬¡ | ~100 æ¡ | ~900 æ¡ | ~3 åˆ†é’Ÿ |
| 10 æ¬¡ | ~200 æ¡ | ~1800 æ¡ | ~5 åˆ†é’Ÿ |
| 20 æ¬¡ | ~400 æ¡ | ~3600 æ¡ | ~10 åˆ†é’Ÿ |

### å‡å°‘æ¿å—æ•°é‡

å¦‚æœåªå…³æ³¨ç‰¹å®šæ¿å—ï¼Œå¯ä»¥ä¿®æ”¹ `src/reddit.py`ï¼š

```python
# ç¼–è¾‘ src/reddit.pyï¼Œæ‰¾åˆ° REDDIT_SUBREDDITS
REDDIT_SUBREDDITS = [
    "LocalLLM",
    "ChatGPT",
    "ArtificialIntelligence",
    # æ³¨é‡Šæ‰ä¸éœ€è¦çš„æ¿å—
    # "LocalLlaMa",
    # "OpenSourceeAI",
]
```

---

## ğŸ› ï¸ å¸¸è§é—®é¢˜

### Q1: Cookies è¿‡æœŸæ€ä¹ˆåŠï¼Ÿ

**ç—‡çŠ¶**ï¼š
- æŠ“å–è¯„è®ºæ—¶å‡ºç° CAPTCHA
- æ—¥å¿—æ˜¾ç¤º "éœ€è¦ç™»å½•" æˆ– "è¢«é™æµ"

**è§£å†³**ï¼š
é‡æ–°å¯¼å‡º cookiesï¼ˆæŒ‰ç…§"ç¬¬ä¸‰æ­¥"é‡æ–°æ“ä½œä¸€æ¬¡ï¼‰

```bash
# åˆ é™¤æ—§çš„ cookies
rm cookies.json

# é‡æ–°å¯¼å‡ºï¼ˆæŒ‰ç…§å‰é¢çš„æ­¥éª¤ï¼‰
# ç„¶åé‡æ–°è¿è¡ŒæŠ“å–
python3 fetch_all.py --reddit-comments
```

### Q2: ChromeDriver ä¸‹è½½å¤±è´¥

**ç—‡çŠ¶**ï¼š
```
Could not reach host. Are you offline?
WebDriver åˆå§‹åŒ–å¤±è´¥
```

**è§£å†³æ–¹æ³• 1**ï¼šæ£€æŸ¥ç½‘ç»œè¿æ¥
```bash
# æµ‹è¯•ç½‘ç»œ
curl https://www.google.com
```

**è§£å†³æ–¹æ³• 2**ï¼šæ‰‹åŠ¨å®‰è£… ChromeDriver
```bash
# Mac
brew install chromedriver

# Ubuntu/Debian
sudo apt-get install chromium-chromedriver

# æ‰‹åŠ¨ä¸‹è½½
# è®¿é—® https://chromedriver.chromium.org/downloads
# ä¸‹è½½å¯¹åº”ç‰ˆæœ¬çš„ ChromeDriver
```

### Q3: æŠ“å–é€Ÿåº¦å¤ªæ…¢

**åŸå› **ï¼š
- Selenium éœ€è¦åŠ è½½å®Œæ•´é¡µé¢
- æ¯ä¸ªæ¿å—éœ€è¦æ»šåŠ¨å¤šæ¬¡

**ä¼˜åŒ–æ–¹æ¡ˆ**ï¼š
1. å‡å°‘æ»šåŠ¨æ¬¡æ•°ï¼š`--max-pages=3`
2. å‡å°‘æ¿å—æ•°é‡ï¼ˆä¿®æ”¹ `src/reddit.py`ï¼‰
3. åªæŠ“å– Postsï¼Œä¸æŠ“å– Comments
4. ä½¿ç”¨å¤šè¿›ç¨‹ï¼ˆé«˜çº§ç”¨æˆ·ï¼‰

### Q4: æ²¡æœ‰æ‰¾åˆ°è¯„è®º

**å¯èƒ½åŸå› **ï¼š
1. æœç´¢å…³é”®è¯åœ¨è¯¥æ¿å—ç¡®å®æ²¡æœ‰è¯„è®º
2. æ‰€æœ‰è¯„è®ºéƒ½è¶…è¿‡30å¤©ï¼ˆè¢«æ—¶é—´è¿‡æ»¤äº†ï¼‰
3. Cookies å¤±æ•ˆï¼Œæ— æ³•åŠ è½½å®Œæ•´å†…å®¹

**æ£€æŸ¥æ–¹æ³•**ï¼š
```bash
# æµ‹è¯•å•ä¸ªæ¿å—ï¼ˆæ˜¾ç¤ºæµè§ˆå™¨çª—å£ï¼‰
python3 -c "
from src.reddit_comments_selenium import RedditCommentsSeleniumFetcher
f = RedditCommentsSeleniumFetcher(headless=False, verbose=True)
f.fetch(subreddits=['LocalLLM'], max_scrolls=3, days_limit=30)
"
```

### Q5: æ•°æ®åº“æ–‡ä»¶è¿‡å¤§

**æ¸…ç†æ—§æ•°æ®**ï¼š
```python
from src.database import DatabaseManager
from datetime import datetime, timedelta

db = DatabaseManager()

# åˆ é™¤è¶…è¿‡90å¤©çš„æ•°æ®
cutoff = datetime.now() - timedelta(days=90)
# éœ€è¦è‡ªå·±å®ç°åˆ é™¤é€»è¾‘ï¼Œæˆ–ç›´æ¥åˆ é™¤æ•°æ®åº“é‡æ–°æŠ“å–
```

**é‡å»ºæ•°æ®åº“**ï¼š
```bash
# å¤‡ä»½
cp data/discussions.db data/discussions.db.backup

# åˆ é™¤
rm data/discussions.db

# é‡æ–°æŠ“å–
python3 fetch_all.py --reddit-comments
```

---

## ğŸ“– è¿›é˜¶ä½¿ç”¨

### è‡ªå®šä¹‰æœç´¢å…³é”®è¯

```bash
# æœç´¢å…¶ä»–å…³é”®è¯
python3 fetch_all.py --reddit-comments  # é»˜è®¤æœç´¢ "ERNIE"

# ä¿®æ”¹ä»£ç æœç´¢å…¶ä»–å…³é”®è¯
# ç¼–è¾‘ fetch_all.pyï¼Œä¿®æ”¹ç¬¬61è¡Œå’Œç¬¬97è¡Œçš„ query='ERNIE'
```

### æ·»åŠ æ›´å¤šæ¿å—

ç¼–è¾‘ `src/reddit.py`ï¼š

```python
REDDIT_SUBREDDITS = [
    # ç°æœ‰æ¿å—
    "LocalLLM", "LocalLlaMa", "ChatGPT",
    "ArtificialIntelligence", "OpenSourceeAI",
    "singularity", "machinelearningnews",
    "SillyTavernAI", "StableDiffusion",

    # æ·»åŠ æ–°æ¿å—
    "MachineLearning",
    "artificial",
    "learnmachinelearning",
]
```

### ä¿®æ”¹æ—¶é—´èŒƒå›´

ç¼–è¾‘ `src/reddit_comments_selenium.py`ï¼Œä¿®æ”¹ `fetch` æ–¹æ³•çš„ `days_limit` é»˜è®¤å€¼ï¼š

```python
def fetch(
    self,
    query: str = "ERNIE",
    ...
    days_limit: int = 60  # æ”¹ä¸º60å¤©
):
```

æˆ–åœ¨è°ƒç”¨æ—¶æŒ‡å®šï¼š
```python
comments_fetcher.fetch(query='ERNIE', days_limit=60)
```

---

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
DiscussionFetcher_v2.0/
â”œâ”€â”€ fetch_all.py              # ä¸»å…¥å£ï¼šä¸€é”®æŠ“å–æ‰€æœ‰æ•°æ®
â”œâ”€â”€ web_server.py            # Web ç•Œé¢æœåŠ¡å™¨
â”œâ”€â”€ start.sh                 # å¿«é€Ÿå¯åŠ¨è„šæœ¬
â”œâ”€â”€ db_manager.py            # æ•°æ®åº“ç®¡ç†å·¥å…·
â”œâ”€â”€ requirements.txt         # ä¾èµ–åˆ—è¡¨
â”œâ”€â”€ .env                     # API å‡­è¯é…ç½®
â”œâ”€â”€ cookies.json            # Reddit cookiesï¼ˆéœ€è‡ªå·±å¯¼å‡ºï¼‰
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ reddit.py           # Reddit Posts æŠ“å–ï¼ˆPRAW APIï¼‰
â”‚   â”œâ”€â”€ reddit_comments_selenium.py  # Reddit Comments æŠ“å–ï¼ˆSeleniumï¼‰
â”‚   â”œâ”€â”€ huggingface.py      # HuggingFace æŠ“å–
â”‚   â”œâ”€â”€ database.py         # æ•°æ®åº“ç®¡ç†
â”‚   â”œâ”€â”€ models.py           # æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ config.py           # é…ç½®ç®¡ç†
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â””â”€â”€ index.html      # Web ç•Œé¢
â”‚   â””â”€â”€ static/
â”‚       â”œâ”€â”€ css/style.css
â”‚       â””â”€â”€ js/app.js
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ discussions.db      # SQLite æ•°æ®åº“ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ USAGE.md            # æœ¬æ–‡æ¡£
    â”œâ”€â”€ README.md           # é¡¹ç›®è¯´æ˜
    â”œâ”€â”€ SELENIUM_GUIDE.md   # Selenium è¯¦ç»†è¯´æ˜
    â””â”€â”€ WEB_USAGE.md        # Web ç•Œé¢è¯´æ˜
```

---

## ğŸ¯ æ¨èå·¥ä½œæµ

### æ—¥å¸¸ä½¿ç”¨ï¼ˆæ¨èï¼‰

```bash
# 1. é¦–æ¬¡ä½¿ç”¨ï¼šå¯¼å‡º cookiesï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰
#    æŒ‰ç…§"ç¬¬ä¸‰æ­¥"æ“ä½œ

# 2. å®‰è£…ä¾èµ–ï¼ˆä»…éœ€ä¸€æ¬¡ï¼‰
pip install -r requirements.txt

# 3. æ¯æ¬¡æŠ“å–æ•°æ®
python3 fetch_all.py --reddit-comments

# 4. æŸ¥çœ‹æ•°æ®ï¼ˆå¯é€‰ï¼‰
python3 db_manager.py stats
python3 db_manager.py export --format excel --output data.xlsx
```

### è‡ªåŠ¨åŒ–éƒ¨ç½²ï¼ˆæ¨èç”Ÿäº§ç¯å¢ƒï¼‰

```bash
# 1. éƒ¨ç½²åˆ°æœåŠ¡å™¨
git clone <repo_url>
cd DiscussionFetcher_v2.0

# 2. é…ç½®ç¯å¢ƒ
pip install -r requirements.txt
cp .env.example .env
# ç¼–è¾‘ .env

# 3. ä¸Šä¼  cookies.json
# åœ¨æœ¬åœ°å¯¼å‡ºï¼Œç„¶åä¸Šä¼ åˆ°æœåŠ¡å™¨
scp cookies.json user@server:/path/to/DiscussionFetcher_v2.0/

# 4. è®¾ç½®å®šæ—¶ä»»åŠ¡
crontab -e
# æ·»åŠ ï¼š0 2 * * * cd /path/to/DiscussionFetcher_v2.0 && python3 fetch_all.py --reddit-comments

# 5. å¯åŠ¨ Web ç•Œé¢ï¼ˆå¯é€‰ï¼‰
```

---

## ğŸ“ æ”¯æŒ

- **æ–‡æ¡£**ï¼šæŸ¥çœ‹é¡¹ç›®ä¸­çš„å…¶ä»– Markdown æ–‡æ¡£
  - `README.md` - é¡¹ç›®æ¦‚è¿°
  - `SELENIUM_GUIDE.md` - Selenium æŠ€æœ¯è¯¦è§£
  - `WEB_USAGE.md` - Web ç•Œé¢ä½¿ç”¨è¯´æ˜

- **é—®é¢˜åé¦ˆ**ï¼šå¦‚æœ‰é—®é¢˜ï¼Œè¯·æ£€æŸ¥"å¸¸è§é—®é¢˜"éƒ¨åˆ†

---

## ğŸ“ æ€»ç»“

### ğŸ¯ ä¸€æ¬¡æ€§è®¾ç½®

1. âœ… å®‰è£…ä¾èµ–ï¼š`pip install -r requirements.txt`
2. âœ… é…ç½® APIï¼ˆå¯é€‰ï¼‰ï¼šç¼–è¾‘ `.env`
3. âœ… å¯¼å‡º Cookiesï¼ˆå¿…éœ€ï¼‰ï¼šä¿å­˜ä¸º `cookies.json`

### ğŸš€ ä¹‹åä½¿ç”¨

```bash
# ä¸€è¡Œå‘½ä»¤ï¼Œå…¨è‡ªåŠ¨æŠ“å–
python3 fetch_all.py --reddit-comments
```

å°±è¿™ä¹ˆç®€å•ï¼ğŸ‰
